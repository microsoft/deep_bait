{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-level PyTorch Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "EPOCHS = 10\n",
    "N_CLASSES=10\n",
    "BATCHSIZE = 64\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "GPU = True\n",
    "\n",
    "LOGGER_URL='msdlvm.southcentralus.cloudapp.azure.com'\n",
    "LOGGER_USRENAME='admin'\n",
    "LOGGER_PASSWORD='password'\n",
    "LOGGER_DB='gpudata'\n",
    "LOGGER_SERIES='gpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable\n",
    "from utils import cifar_for_library, yield_mb, create_logger, Timer\n",
    "from nb_logging import NotebookLogger, output_to, error_to\n",
    "from gpumon.influxdb import log_context\n",
    "import codecs\n",
    "\n",
    "from influxdb import InfluxDBClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = InfluxDBClient(LOGGER_URL, 8086, LOGGER_USRENAME, LOGGER_PASSWORD, LOGGER_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_id = os.getenv('AZ_BATCH_NODE_ID', default='node')\n",
    "task_id = os.getenv('AZ_BATCH_TASK_ID', default='pytorch')\n",
    "job_id = os.getenv('AZ_BATCH_JOB_ID', default='pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = create_logger(client, node_id=node_id, task_id=task_id, job_id=job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.__stdout__ = codecs.getwriter(\"utf-8\")(sys.__stdout__.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_teminal_logger = NotebookLogger(sys.stdout.session, sys.stdout.pub_thread, sys.stdout.name, sys.__stdout__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpumon.influxdb_gpu_logger:Logging GPU to Database msdlvm.southcentralus.cloudapp.azure.com\n",
      "INFO:gpumon.influxdb_gpu_logger:['influxdb_gpu_logger.py', 'msdlvm.southcentralus.cloudapp.azure.com', '8086', 'admin', 'password', 'gpudata', 'gpu', '--node_id=node', '--task_id=pytorch', '--job_id=pytorch']\n"
     ]
    }
   ],
   "source": [
    "rst_out = output_to(nb_teminal_logger)\n",
    "rst_err = error_to(nb_teminal_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"PyTorch: \", torch.__version__)\n",
    "print(\"Numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Big impact on training-time (from 350 to 165s)\n",
    "torch.backends.cudnn.benchmark=True # enables cudnn's auto-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = path.join(os.getenv('AZ_BATCHAI_INPUT_DATASET'), 'cifar-10-batches-py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SymbolModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SymbolModule, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 50, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(50, 50, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(50, 100, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(100, 100, kernel_size=3, padding=1)\n",
    "        # feature map size is 8*8 by pooling\n",
    "        self.fc1 = nn.Linear(100*8*8, 512)\n",
    "        self.fc2 = nn.Linear(512, N_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" PyTorch requires a flag for training in dropout \"\"\"\n",
    "        x = self.conv2(F.relu(self.conv1(x)))\n",
    "        x = F.relu(F.max_pool2d(x, kernel_size=2, stride=2))\n",
    "        x = F.dropout(x, 0.25, training=self.training)\n",
    "\n",
    "        x = self.conv4(F.relu(self.conv3(x)))\n",
    "        x = F.relu(F.max_pool2d(x, kernel_size=2, stride=2))\n",
    "        x = F.dropout(x, 0.25, training=self.training)\n",
    "\n",
    "        x = x.view(-1, 100*8*8)   # reshape Variable\n",
    "        x = F.dropout(F.relu(self.fc1(x)), 0.5, training=self.training)\n",
    "        # nn.CrossEntropyLoss() contains softmax, don't apply twice\n",
    "        #return F.log_softmax(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model(m):\n",
    "    # Implementation of momentum:\n",
    "    # v = \\rho * v + g \\\\\n",
    "    # p = p - lr * v\n",
    "    opt = optim.SGD(m.parameters(), lr=LR, momentum=MOMENTUM)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return opt, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train set...\n",
      "Preparing test set...\n",
      "Done.\n",
      "(50000, 3, 32, 32) (10000, 3, 32, 32) (50000,) (10000,)\n",
      "float32 float32 int64 int64\n",
      "CPU times: user 980 ms, sys: 880 ms, total: 1.86 s\n",
      "Wall time: 1.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Data into format for library\n",
    "x_train, x_test, y_train, y_test = cifar_for_library(data_path, channel_first=True)\n",
    "# Torch-specific\n",
    "y_train = y_train.astype(np.int64)\n",
    "y_test = y_test.astype(np.int64)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
    "print(x_train.dtype, x_test.dtype, y_train.dtype, y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.76 s, sys: 2.79 s, total: 4.55 s\n",
      "Wall time: 9.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sym = SymbolModule()\n",
    "sym.cuda() # CUDA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 210 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer, criterion = init_model(sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Training took 107.903 sec.\n"
     ]
    }
   ],
   "source": [
    "with Timer() as t:\n",
    "    with log_context(LOGGER_URL, 'admin', LOGGER_USRENAME, LOGGER_PASSWORD, LOGGER_DB, LOGGER_SERIES, \n",
    "                     node_id=node_id, task_id=task_id, job_id=job_id):\n",
    "        # Sets training = True\n",
    "        sym.train()  \n",
    "        for j in range(EPOCHS):\n",
    "            for data, target in yield_mb(x_train, y_train, BATCHSIZE, shuffle=True):\n",
    "                # Get samples\n",
    "                data = Variable(torch.FloatTensor(data).cuda())\n",
    "                target = Variable(torch.LongTensor(target).cuda())\n",
    "                # Init\n",
    "                optimizer.zero_grad()\n",
    "                # Forwards\n",
    "                output = sym(data)\n",
    "                # Loss\n",
    "                loss = criterion(output, target)\n",
    "                # Back-prop\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # Log\n",
    "            print(j)\n",
    "print('Training took %.03f sec.' % t.interval)\n",
    "logger('training duration', value=t.interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 400 ms, sys: 232 ms, total: 632 ms\n",
      "Wall time: 631 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test model\n",
    "# Sets training = False\n",
    "sym.eval()\n",
    "n_samples = (y_test.shape[0]//BATCHSIZE)*BATCHSIZE\n",
    "y_guess = np.zeros(n_samples, dtype=np.int)\n",
    "y_truth = y_test[:n_samples]\n",
    "c = 0\n",
    "for data, target in yield_mb(x_test, y_test, BATCHSIZE):\n",
    "    # Get samples\n",
    "    data = Variable(torch.FloatTensor(data).cuda())\n",
    "    # Forwards\n",
    "    output = sym(data)\n",
    "    pred = output.data.max(1)[1].cpu().numpy().squeeze()\n",
    "    # Collect results\n",
    "    y_guess[c*BATCHSIZE:(c+1)*BATCHSIZE] = pred\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.777243589744\n"
     ]
    }
   ],
   "source": [
    "acc=sum(y_guess == y_truth)/len(y_guess)\n",
    "print(\"Accuracy: \", acc)\n",
    "logger('accuracy', value=acc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
